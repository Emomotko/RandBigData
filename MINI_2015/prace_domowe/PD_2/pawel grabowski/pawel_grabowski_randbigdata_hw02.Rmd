---
#title: "pawel_grabowski_randbigdata_hw02"
author: "grabowski"
date: "Thursday, March 19, 2015"
output: html_document
---



<center><h3>Harvesting and Analyzing Tweets</h3></center>
The aim of this exercise is to provide analysys of tweets that were associated with phrase **Champion's League**. Tweets were downloaded from Twitter Api using **streamR** library and filterStream function which download tweets that meet specific conditions(key word, localisation, language). 


<h4>Libraries used in below codes: </h4>
```{r, warning=FALSE, message=FALSE}
library(streamR)
library(ROAuth)
library(dplyr)
library(ggplot2)
library(gridExtra)
library(wordcloud)
library(stringi)
library(tm)
```


<h4>Code for downloading tweets</h4>
```{r, eval=FALSE}
requestURL <- "https://api.twitter.com/oauth/request_token"
accessURL <- "https://api.twitter.com/oauth/access_token"
authURL <- "https://api.twitter.com/oauth/authorize"
consumerKey <- "QTyOuPErIAHzqnQ5Zk4vQlixT"
consumerSecret <- "c6jNRexixiNQVCG19vRqiURvZJFqK1PV1zZVMTbOdeD9jgsjwT"
oauthKey <- "secretsecresivegotasecret"
oauthSecret <- "roboto"


paczka <- OAuthFactory$new(consumerKey = consumerKey, consumerSecret = consumerSecret, 
                           oauthKey = oauthKey, oauthSecret = oauthSecret,
                           requestURL = requestURL, accessURL = accessURL, authURL = authURL)

paczka$handshake(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl"))

filterStream( file=paste0("liga",Sys.Date(),".json"), 
              track=c( "champions league"), 
              timeout=2*3600, oauth=paczka, 
              )
```


<h4>Parsing tweets.</h4>
```{r, cache=TRUE}
parsedTweets <- parseTweets(".\\liga2015-03-18.json",simplify = FALSE, verbose = TRUE)

```


<h4>Comparison of users' and tweets language </h4>
```{r,warning=FALSE, message=FALSE, cache=TRUE}
table_lang <- table(parsedTweets$lang)
table_user_lang <- table(parsedTweets$user_lang)
df_lang <- as.data.frame(table_lang)
df_user_lang <- as.data.frame(table_user_lang)
df_lang_comparison <- left_join(df_lang, df_user_lang, by="Var1")
names(df_lang_comparison) <- c("language", "tweet_lang_count", "user_lang_count")
df_lang_comparison <- na.omit(df_lang_comparison)

df_temp <- df_lang_comparison


df_lang_comparison$language <-factor(df_lang_comparison$language, levels=df_lang_comparison[order(df_lang_comparison$tweet_lang_count), "language"])

y1 <-ggplot(df_lang_comparison, aes(x=language, y=tweet_lang_count)) + 
    geom_bar(stat="identity") + xlab("Count of tweets languages") +
    coord_flip()


df_lang_comparison$language <-factor(df_lang_comparison$language, levels=df_lang_comparison[order(df_lang_comparison$user_lang_count), "language"])

y2 <-ggplot(df_lang_comparison, aes(x=language, y=user_lang_count)) + 
    geom_bar(stat="identity") + xlab("Count of user languages") +
    coord_flip()

grid.arrange(y1, y2, ncol=2)


df_temp1 <- df_temp[,1:2]
df_temp2 <- df_temp[,-2]
names(df_temp1) <- names(df_temp2)
df_temp <- rbind(df_temp1, df_temp2)
names(df_temp) <- c("x","y")
df_temp$z <- rep(c("twitter_lang", "user_lang"), each=dim(df_temp)[1]/2)

ggplot(df_temp, aes(x=x,y=y,fill=z)) + geom_bar(stat="identity", position="dodge")
```


<h4>Cleaning tweets</h4>
```{r, cache=FALSE}
parsedTweets2 <- parsedTweets[,1]
#tarnforming to lower letters
parsedTweets2 <- sapply(parsedTweets2, stri_trans_tolower,
                        USE.NAMES=FALSE)
# deleting url link
parsedTweets2 <- sapply(parsedTweets2, function(x) stri_replace_all_regex(x,"http\\S+\\s*",""),
                        USE.NAMES=FALSE)
# deleting @users
parsedTweets2 <- sapply(parsedTweets2, function(x) stri_replace_all_regex(x,"@\\w+",""),
                        USE.NAMES=FALSE)
# removing numbers
parsedTweets2 <- sapply(parsedTweets2, function(x) stri_replace_all_regex(x,"[[:digit:]]",""),
                        USE.NAMES=FALSE)
# removing stopwords with tm library
parsedTweets2 <- sapply(parsedTweets2, removeWords, stopwords("english"),
                        USE.NAMES=FALSE)
#remove puntuation
parsedTweets2 <- sapply(parsedTweets2, function(x) removePunctuation(x),
                        USE.NAMES=FALSE)

allwords <- unlist(stri_extract_all_words(parsedTweets2))
allwords <- allwords[sapply(allwords,nchar)>2]



```   

<h4>Barplot of most used words.</h4>
```{r}
tt <- head(sort(table(allwords), decreasing=T), n=20)
tt2 <- head(sort(table(allwords), decreasing=T), n=40)
# barplot(tt)

df <- data.frame(name=names(tt), count=tt)
lengthx <- dim(df)[1]
ggplot(df,aes(x=factor(name), y=count)) + geom_bar(stat="identity") + theme(axis.text.x=element_text(angle=45, hjust=1))

```

<h4>Word Cloud.</h4>
```{r}
df2 <- data.frame(name=names(tt2), count=tt2)
wordcloud(df2[,1],df2[,2], colors=topo.colors(40))
```













