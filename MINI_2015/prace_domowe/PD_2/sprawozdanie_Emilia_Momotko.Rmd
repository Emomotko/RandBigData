---
title: "WordCloud"
output: html_document
---
# <span style="color:navy">1. Cel raportu.</span>

Celem niniejszego raportu jest przeanalizowanie tweetów, zwi¹zanych z dyscyplin¹ sportow¹: tenisem. Na potrzeby badania zebra³am 5831 tweetów; s³owa kluczowe, które wykorzysta³am do odnalezienia odpowiednich tweetów to: **"tennis","wimbledon","australian open","french open"**.

Pakiety:

```{rMerge, eval=TRUE,results='hide',warning=FALSE,message=FALSE}
library(streamR)
library(ROAuth)
library(wordcloud)
library(stringi)
library(RColorBrewer)
library(tm)
```


```{r, echo=FALSE,results='hide',cache=TRUE}
setwd("D:\\Moje dokumenty\\Emilka\\SMAD\\RAndBigData\\pd2")
parsedTwees <- parseTweets("tennis.json", simplify = FALSE, verbose = TRUE)
```

# <span style="color:navy">2. Oczyszczanie danych.</span>

Nastêpnym krokiem by³o oczyszczenie danych. Z treœci tweetów wyci¹gnê³am s³owa, pozby³am siê linków, nicków i adresów e-mail.

Najpierw wyci¹gamy pierwsz¹ kolumnê z wczytanej ramki danych.

```{rChunk,eval=TRUE,results='hide',warning=FALSE,message=FALSE,cache=TRUE}

tweety<-parsedTwees[,1]

```

Nastêpnie usuwamy wszystkie niepotrzebne znaki, cyfry i s³owa, które nie maj¹ wiêkszego znaczania przy analizie tweetów.

```{rChunk2, eval=TRUE,results='hide',warning=FALSE,message=FALSE,cache=TRUE}

modified<-stri_extract_all_regex(tweety,"((\\w)|(\\s)|[:punct:])+")
modified<-unlist(lapply(modified,stri_flatten," "))

modified<-stri_replace_all_regex(modified,"http((\\w)|([:punct:]))+","")

modified<-stri_replace_all_regex(modified,"@(\\w)+(?=((\\s)|([:punct:])))","")
modified<-stri_replace_all_regex(modified,"((\\w)|([:punct:]))+(@|[0-9])((\\w)|([:punct:]))+","")

slowa<-unlist(stri_extract_all_words(modified))
slowa<-stri_trans_tolower(slowa)

slowa<-slowa[!(slowa%in%stopwords("English"))]
irrelevant<-c('u','i',"ain't","i'm","a","im","you","he" ,"about", "above", "across", "after",
              "afterwards", "again", "against", "all", "almost", "alone",
              "along", "already", "also","although","always","am","among",
              "amongst", "amoungst", "amount",  "an", "and", "another", "any",
              "anyhow","anyone","anything","anyway", "anywhere", "are", "around",
              "as",  "at", "back","be","became", "because","become","becomes",
              "becoming", "been", "before", "beforehand", "behind", "being",
              "below", "beside", "besides", "between", "beyond", "bill", "both",
              "bottom","but", "by", "call", "can", "cannot", "cant", "co", "con",
              "could", "couldnt", "cry", "de", "describe", "detail", "do",
              "done", "down", "due", "during", "each", "eg", "eight", "either",
              "eleven","else", "elsewhere", "empty", "enough", "etc", "even",
              "ever", "every", "everyone", "everything", "everywhere", "except", 
              "few", "fifteen", "fify", "fill", "find", "fire", "first", "five",
              "for", "former", "formerly", "forty", "found", "four", "from",
              "front", "full", "further", "get", "give", "go", "had", "has", 
              "hasnt", "have", "he", "hence", "her", "here", "hereafter",
              "hereby", "herein", "hereupon", "hers", "herself", "him", 
              "himself", "his", "how", "however", "hundred", "ie", "if", "in",
              "inc", "indeed", "interest", "into", "is", "it", "its", "itself",
              "keep", "last", "latter", "latterly", "least", "less", "ltd",
              "made", "many", "may", "me", "meanwhile", "might", "mill", "mine",
              "more", "moreover", "most", "mostly", "move", "much", "must", "my",
              "myself", "name", "namely", "neither", "never", "nevertheless", 
              "next", "nine", "no", "nobody", "none", "noone", "nor", "not", 
              "nothing", "now", "nowhere", "of", "off", "often", "on", "once", 
              "one", "only", "onto", "or", "other", "others", "otherwise", "our",
              "ours", "ourselves", "out", "over", "own","part", "per", "perhaps",
              "please", "put", "rather", "re", "same", "see", "seem", "seemed",
              "seeming", "seems", "serious", "several", "she", "should", "show",
              "side", "since", "sincere", "six", "sixty", "so", "some", 
              "somehow", "someone", "something", "sometime", "sometimes",
              "somewhere", "still", "such", "system", "take", "ten", "than",
              "that", "the", "their", "them", "themselves", "then", "thence",
              "there", "thereafter", "thereby", "therefore", "therein",
              "thereupon", "these", "they", "thickv", "thin", "third", "this",
              "those", "though", "three", "through", "throughout", "thru",
              "thus", "to", "together", "too", "top", "toward", "towards",
              "twelve", "twenty", "two", "un", "under", "until", "up", "upon",
              "us", "very", "via", "was", "we", "well", "were", "what",
              "whatever", "when", "whence", "whenever", "where", "whereafter",
              "whereas", "whereby", "wherein", "whereupon", "wherever",
              "whether", "which", "while", "whither", "who", "whoever", "whole",
              "whom", "whose", "why", "will", "with", "within", "without",
              "would", "yet", "you", "your", "yours", "yourself", "yourselves",
              "the","amp")

slowa<-slowa[unlist(lapply(slowa,nchar))>2]

slowa<-slowa[!(slowa%in%irrelevant)]
ile<-sort(table(slowa),decreasing = TRUE)
```


Tworzymy ramkê danych, w której znajd¹ siê s³owa oraz liczba ich wyst¹pieñ w analizowanym tekœcie.

```{rChunk3, eval=TRUE,results='hide',warning=FALSE,message=FALSE,cache=TRUE}

ramka<-data.frame(slowo=names(ile),czestosc=ile,row.names=NULL)

```

```{rChunk4, echo=FALSE,results='hide',cache=TRUE}
kolory <- brewer.pal(8,"Dark2")
```

# <span style="color:navy">3. Wyniki.</span>

Po przeanalizowaniu danych, skorzysta³am z pakietu wordcloud, aby stworzyæ tzw. chmurê s³ów:
```{rChunk 5, fig.align='center',echo=FALSE}
wordcloud(ramka[,1],ramka[,2], scale=c(4,0.1),min.freq=3,
          max.words=100, random.order=FALSE, rot.per=.20, colors=kolory)
```

Teraz przyjrzyjmy siê jak czêœtoœæ wystêpowania s³ów w tweetach prezentuje siê na wykresie s³upkowym:
```{rChunk9, fig.align='center',echo=FALSE}

x<-barplot(ile[1:10],col=c("lightcoral"),width=0.5,ylim=c(0,300),main="Czêstoœæ wystêpowania s³ów",cex.names=0.85)
text(x, ile[1:10], labels = format(ile[1:10], 2),
     pos = 3, cex = .75)

```


Jakie wnioski mo¿emy wyci¹gn¹æ, patrz¹c na powy¿sz¹ chnurê i wykres? Otó¿ wiêkszoœci ludziom sport kojarzy siê bardzo pozytywnie, dominuj¹ce s³owa s¹ to "like", "love","good","happy".
