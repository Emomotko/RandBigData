---
title: "Analiza tweetów"
author: "Miko³aj Waœniewski"
date: "Tuesday, March 18, 2015"
output: pdf_document
---
#Wstep
Do analizy postanowi³em wzi¹æ tweety wys³ane w Warszwie i okolicach.
Podczaas selekcji tweetow ustawi³em parametr `locations= c(20.75,52,21.25,52.5)`.
Tweety zbiera³em cztery razy po jednej godzinie, uda³e mi sie zebraæ 2202 tweetów.

```{r,echo=FALSE,warning=FALSE,message=FALSE,include=FALSE}
library("twitteR")
library("streamR")
library("ROAuth")
library("ggplot2")
library("stringi")
library("ggmap")
library("tm")
library("wordcloud")
setwd("C:/Users/Miko³aj/Documents")
Tweets <- parseTweets("warszawa.json", simplify = FALSE, verbose = TRUE)
Tweets2 <- parseTweets("warszawa2.json", simplify = FALSE, verbose = TRUE)
Tweets3 <- parseTweets("warszawa3.json", simplify = FALSE, verbose = TRUE)
Tweets4 <- parseTweets("warszawa4.json", simplify = FALSE, verbose = TRUE)
Tweets<-rbind(Tweets,Tweets2,Tweets3,Tweets4)
```

#Jezyki

Na pocz¹tku sporz¹dzi³em wykres jezykow uzytkowników pobranych tweetow 
(zmienna `user_lang`).

```{r, echo=FALSE}
jezyki_uzyt<-table(Tweets$user_lang)
y<-as.vector(jezyki_uzyt)

ggplot(data.frame("x"=names(jezyki_uzyt),"y"=y),aes(x=factor(names(jezyki_uzyt)), y=y))+
   geom_bar(stat="identity")+xlab("jezyki uzytkownikow")+ylab("liczba tweetow")
```

Nastêpnie sporzadzie³ wykres jezykow w jakich tweety zosta³y napisne 
(zmienna 'lang').

```{r, echo=FALSE}
jezyki<-table(Tweets$lang)
jezyki_tweetow<-names(jezyki)
y<-as.vector(jezyki)
ggplot(data.frame("x"=jezyki_tweetow,"y"=y),aes(x=factor(jezyki_tweetow), y=y))+
   geom_bar(stat="identity")+xlab("jezyki tweetow")+ylab("liczba tweetow")
```

#S³owa w tweetach

Tweety napisane w jezyju angielskim podzieli³em na s³owa i na wykresie 
zamieœci³em 15 najczêsciej wystêpujacych s³ów.

```{r}
tweets <- Tweets[Tweets$lang %in% c('en','en-gb','en-GB','uk'),1]
text1 <- sapply(tweets, stri_trans_tolower)
# usuniecie linkow
text1 <- sapply(text1, function(x){ 
   stri_replace_all_regex(x,"http[^ ]+|www[^ ]+","") }, USE.NAMES=FALSE)
# usuniecie hashtagow
text1 <- sapply(text1, function(x){ stri_replace_all_regex(x,"#[^ ]*","") },
                                                          USE.NAMES=FALSE)
# usuniecie odnosnkow do innego uyztkownika tweetera
text1 <- sapply(text1, function(x){ stri_replace_all_regex(x,"@[^ |^\\n|]+","") },
                                                          USE.NAMES=FALSE)
# usuniecie cyfr
text1 <- sapply(text1, function(x){ stri_replace_all_regex(x,"[0-9]*","") },
                                                            USE.NAMES=FALSE)
text1<-sapply(text1,removeWords,stopwords("english"),USE.NAMES=FALSE)
text1<-sapply(text1,removePunctuation,USE.NAMES=FALSE)
text1<-sapply(text1,stripWhitespace,USE.NAMES=FALSE)
without<-c("can","will","hemmings","hi","mutch","much","luke","ll","x","u")
words<-unlist(lapply(text1, stri_extract_all_words))
words<-words[!words%in%without] 
words<-unname(words)
w<-head(sort(table(words), decreasing=T), n=15)

ggplot(data.frame("x"=names(w),"y"=w),aes(x=factor(names(w)), y=w),)+
   geom_bar(stat="identity")+xlab("slowa")+ylab("liczba s³ów")+ 
   theme(axis.text.x = element_text(angle = 90, hjust = 1))

```

Nastêpnie utworzy³em chmurê 15 najczêsciej wystêpuj¹cych s³ów.

```{r}
w2<-do.call(paste, c(as.list(words), sep=" "))
corp<-Corpus(VectorSource(w2))
term.matrix <- TermDocumentMatrix(corp)
term.matrix <- as.matrix(term.matrix)
commonality.cloud(term.matrix,max.words=15,random.order=FALSE)
```

#Hashtagi

Najpopularniejsze hashtagi:

```{r}
hash_tag<-unlist(stri_extract_all_regex(Tweets$text,"#[^ |^\\n|]+"))
head(sort(table(na.omit(hash_tag)), decreasing=TRUE),n=10)

```

#Mapa

Na mape nanios³em miejsca, z których zosta³u wys³ane tweety.

```{r,warning=FALSE,message=FALSE}
lon<-Tweets$lon
lat<-Tweets$lat
lat<-lat[!is.na(lat)]
lon<-lon[!is.na(lon)]
qmap(location = "warsaw",color = 'bw',zoom = 12, messaging = TRUE, source = "google") +
   geom_point(data=data.frame("x"=lon,"y"=lat),aes(x=lon, y=lat))
```

